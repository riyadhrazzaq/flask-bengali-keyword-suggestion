{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_emotion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02oIlwEeb9Q-",
        "colab_type": "text"
      },
      "source": [
        "mount and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NKljjVbprlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmA8kvXsxggg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import re\n",
        "import pprint\n",
        "import gensim\n",
        "import logging\n",
        "import pickle\n",
        "# SKLEARN\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "# KERAS\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation,Dense,Dropout,Embedding,GRU,LSTM\n",
        "from keras import utils\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.models import load_model,model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blL7spEKssUP",
        "colab_type": "text"
      },
      "source": [
        "Content\n",
        "* load data\n",
        "* preprocess\n",
        "* tokenize\n",
        "* padding\n",
        "* lstm\n",
        "* predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdeBaMhzOF2S",
        "colab_type": "text"
      },
      "source": [
        "# DATA: AMAZON FINE FOOD\n",
        "active"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByQDbg70QDxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sqlite3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmx6J9JPOtlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtHpy9eSOKTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp '/content/drive/My Drive/Colab Notebooks/kaggle.json' ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFmDPQWdO-mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d snap/amazon-fine-food-reviews --unzip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4hXFayCQJV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "con = sqlite3.connect('/content/database.sqlite')\n",
        "df = pd.read_sql_query(\"SELECT * FROM Reviews\", con)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDoGE_BpQYJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['Id','ProductId','UserId','ProfileName','Time'],axis=1,inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDmNCi9nRQDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Usefulness'] = (df['HelpfulnessNumerator'] / df['HelpfulnessDenominator']).apply(lambda x: 'useful' if x>0.7 else 'useless')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jluX4hZ0SodY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['sentiment'] = df['Score'].apply(lambda x: 'positive' if x>3 else ('negative' if x<3 else 'neutral'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-iIb7LRI7JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yDPbrjWTIol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns = ['upvote','totalvote','score','summary','content','usefulness','sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ0X7O8DJGqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji6Wg1ojV_L3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def describe(amzn):\n",
        "    emotions = amzn.sentiment.unique()\n",
        "    emotions_details = []\n",
        "    for emo in emotions:\n",
        "        info = {}\n",
        "        info['feeling'] = emo\n",
        "        info['count'] = len(amzn[amzn['sentiment']==emo])\n",
        "        info['mean_len'] = np.mean([len(x.split()) for x in amzn[amzn['sentiment']==emo]['content']])\n",
        "        emotions_details.append(info)\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    pp.pprint(emotions_details)\n",
        "describe(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8rW2o_MJR6Z",
        "colab_type": "text"
      },
      "source": [
        "since dataset is more biased towards positive reviews, let's randomly select 82037 positive, 82037 negative, 42640 neutral"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG7ckA3kJpES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_rev = df[df['sentiment']=='positive'].sample(n=82037,axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwjUByVuKaJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amzn = df.drop(df[df.sentiment == 'positive'].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUY09uO0MAAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amzn = amzn.append(pos_rev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTN4mRFAMVPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "describe(amzn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E4GdV9bMawU",
        "colab_type": "text"
      },
      "source": [
        "voila!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_EE_AntRmdd",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "skip for amzn, preprocessed *csv* is saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtVavOl7zxIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopword = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtMrlw4O5KI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(stopword)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OFMoBnI12jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(text):\n",
        "    \"\"\"Remove link,user, special characters and stopwords\n",
        "    params: string.\n",
        "    returns: string\n",
        "    \"\"\"\n",
        "    stemmer = SnowballStemmer(language='english')\n",
        "    text = re.sub('@\\S+|https?:\\S+|http?:\\S|\\W+', ' ', str(text).lower()).strip()\n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stopword:\n",
        "            token = stemmer.stem(token)\n",
        "            tokens.append(token)\n",
        "\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SssLJtJF2Lih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "amzn.content = amzn.content.apply(lambda x: clean(x)) # x = each tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duqnmezlNUjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amzn.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpXoFSCSQOOY",
        "colab_type": "text"
      },
      "source": [
        "saving amzn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlE13IM7QXxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amzn.to_csv('/content/drive/My Drive/Colab Notebooks/AI_LAB_PROJECT/Data/amzn.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u72k03dL-uIl",
        "colab_type": "text"
      },
      "source": [
        "**Load AMZN** \\\n",
        "it is already processed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fmaRBZGhcgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amzn = pd.read_csv('/content/drive/My Drive/Colab Notebooks/AI_LAB_PROJECT/Data/amzn.csv')\n",
        "amzn.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNq6YHrjHxBO",
        "colab_type": "text"
      },
      "source": [
        "train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0MRxwG0YdlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,test = train_test_split(amzn,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtTyf2A-q_EH",
        "colab_type": "text"
      },
      "source": [
        "# Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_NK0JR8-du1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SENT_LEN = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqik1B7aIIwb",
        "colab_type": "text"
      },
      "source": [
        "Tokenization and Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exoCUsr0LKMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tk = Tokenizer(num_words=50000)\n",
        "tk.fit_on_texts(amzn.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibd25N01rQ6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_WORDS = len(tk.word_index)+1\n",
        "print(len(tk.word_index)+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0gnmwylmoA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tk.texts_to_sequences(train.content)\n",
        "X_train = pad_sequences(X_train,maxlen=SENT_LEN,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN9PBrXArqdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S7hd9kBQF7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = tk.texts_to_sequences(test.content)\n",
        "X_test = pad_sequences(X_test,maxlen=SENT_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3YjGuRfIMxl",
        "colab_type": "text"
      },
      "source": [
        "One Hot Encoding: Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdoX7_ZSR5tE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.array(amzn.sentiment).reshape(-1,1)\n",
        "y_train = np.array(train.sentiment).reshape(-1,1)\n",
        "y_test = np.array(test.sentiment).reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f-rVaeRXofN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onehotenc = OneHotEncoder(categories=\"auto\",handle_unknown='ignore')\n",
        "onehotenc.fit(y)\n",
        "y_train = onehotenc.transform(y_train)\n",
        "y_test = onehotenc.transform(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ9D5sps43kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/AI_LAB_PROJECT/Data/ohe.pickle', 'wb') as handle:\n",
        "    pickle.dump(onehotenc, handle, protocol=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VHhazZ_tBID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DbX44j90lHo",
        "colab_type": "text"
      },
      "source": [
        " defining model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rmvU4RhDCPQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS,100,input_length=X_train.shape[1])) # PROBLEM\n",
        "model.add(LSTM(100,dropout=0.2,recurrent_dropout=0.2))\n",
        "model.add(Dense(y_test.shape[1],activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Vd9ZLEMRCPQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
        "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLqXAVNe0n8M",
        "colab_type": "text"
      },
      "source": [
        "fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbcnvbbFgdDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "lstm_3= model.fit(X_train,y_train,batch_size=128,epochs=5,validation_data=(X_test,y_test),verbose=1,callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsSZcnYY0rfi",
        "colab_type": "text"
      },
      "source": [
        "saving trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzyMKp_9VJJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/Colab Notebooks/AI_LAB_PROJECT/Data/lstm_3_amzn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LJL1PUoICPRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(lstm_3.history['acc'], label='train')\n",
        "plt.plot(lstm_3.history['val_acc'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nycD0zPoHI30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(text):\n",
        "    \"\"\"\n",
        "    returns:\n",
        "    pr = [negative,neutral,positive]\n",
        "    f_label = sentiment label\n",
        "    s_label\n",
        "    \"\"\"\n",
        "    # Tokenize text\n",
        "    x_test = tk.texts_to_sequences([text])\n",
        "    x_test = pad_sequences(x_test, maxlen=SENT_LEN)\n",
        "    # Predict\n",
        "    pr = model.predict([x_test])\n",
        "    # taking top two of final predictions\n",
        "    f_score = np.max(pr)\n",
        "    f_label = onehotenc.inverse_transform(pr)\n",
        "    return (pr,f_label,s_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntsjj9nU0yps",
        "colab_type": "text"
      },
      "source": [
        "predicting samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6qj1WC0GnQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = \"Every once in a while, especially after a longer cook time with liquids still present, some leaking will happen from bag into the slow cooker. But at least it is minimal and cleanup is still super easy!\"\n",
        "n = \"These were horrible. bought them for my crockpot. every time i used them (on low heat) they would burn onto the crockpot and it would rip as i was pulling it out. complete mess! do not buy these\"\n",
        "print(predict(p))\n",
        "print(predict(n))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZfNL3he01NE",
        "colab_type": "text"
      },
      "source": [
        "exporting lstm `model` as HDF5 file, `tokenizer` as .pickle, `onehotenc` as .pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKcW7WUQ3xea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/My Drive/Colab Notebooks/AI_LAB_PROJECT/Data/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tk, handle, protocol=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb6UexW9TzgI",
        "colab_type": "text"
      },
      "source": [
        "# Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ58uxzGWFd4",
        "colab_type": "text"
      },
      "source": [
        "save weight + architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQic8hA0T1Uz",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "del model  # deletes the existing model\n",
        "\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "model = load_model('my_model.h5')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgW6WgrGWKfy",
        "colab_type": "text"
      },
      "source": [
        "Save only architecture\n",
        "```\n",
        "# save as JSON\n",
        "json_string = model.to_json()\n",
        "\n",
        "# save as YAML\n",
        "yaml_string = model.to_yaml()\n",
        "```\n",
        "Save JSON \n",
        "```\n",
        "import json\n",
        "my_details = {\n",
        "    'name': 'John Doe',\n",
        "    'age': 29\n",
        "}\n",
        "with open('personal.json', 'w') as json_file:\n",
        "    json.dump(my_details, json_file)\n",
        "```\n",
        "Load\n",
        "```\n",
        "# model reconstruction from JSON:\n",
        "from keras.models import model_from_json\n",
        "model = model_from_json(json.dumps(json_string)\n",
        "\n",
        "# model reconstruction from YAML:\n",
        "from keras.models import model_from_yaml\n",
        "model = model_from_yaml(yaml_string)\n",
        "```"
      ]
    }
  ]
}